# nolint start: line_length_linter
#' Run automatic quality control on a deployment
#'
#' `qc_deployment()` will:
#' 1. Read the calibrated dissolved oxygen and conductivity output from
#' HOBOware.
#' 2. Read and parse the associated Details file.
#' 3. Reformat and merge the data files.
#' 4. Add automatic flags, and create columns for manual QC
#' 5. Write the data and metadata.
#' 6. If `report = TRUE` it will call [make_deployment_report()] to make
#' and interactive HTML report with plots for QAQC.
#'
#' `qc_deployment()` assumes the files are arranged in a specific
#' [file structure](https://docs.google.com/document/d/1kJttcEXzpNNknGwjkVwdYHw9LzZyjJ-FaX0CrU7H7NU/edit#heading=h.s6vs4d7vj0cn).
#'
#' @section Supported import types:
#'
#' There are currently 3 separate import functions to handle different formats
#' of the data. They are:
#'
#' **0 - Basic CSV Import**
#'
#' This import requires a CSV file and a YAML (`.yml`) file. It is intended to
#' be a fall back / future proof import with a supper simple format.
#'
#' It should work with input columns names as Hoboware creates when calibrating
#' the MX801 logger or the U24 and U26 loggers; as well as with the canonical
#' names:  "Date_Time", "Raw_DO", "Temp_DOLog", "DO", "DO_Pct_Sat",
#' "High_Range", "Temp_CondLog", "Spec_Cond", "Salinity",
#' "Depth", "Latitude", and "Longitude".  The last three columns (Depth,
#' Latitude, and Longitude) are optional.
#'
#'  Note: when combining data from the U24 and U26 loggers into
#'  a single sheet for use with this function the two temperature columns
#'  will have to be manually renamed to "Temp_CondLog", and "Temp_DOLog".
#'
#'  The YAML file will should look something
#'  like this:
#'  ```
#'  calibration_start: 2025-01-02 14:50:02
#'  calibration_end: 2025-01-04 15:10:02
#'  do_device:
#'    product: MX801
#'    serial_number: 22145888
#'  cond_device:
#'    product: MX801
#'    serial_number: 22145888
#'  timezone: EST
#' ```
#'  **1 - U24 and U26 loggers**
#'
#'  This is the first import that was supported by the **BuzzardsBay** package.
#'  It is for when two loggers (U24 and U26) are used to record the salinity
#'  and dissolved oxygen data.
#'
#'  It expects two CSV (ending in `.csv`) files along with
#'  two details files (ending in `details.txt`).
#'
#'  One file of each type should contain `DO_` somewhere in the name indicating
#'  that it is from a dissolved oxygen logger; and one file of each type should
#'  contain either `SAL_` or `COND_` in the name indicating it is from a
#'  salinity/conductivity logger.
#'
#'  The naming requirements are not case sensitive.
#'
#'  **2 - MX801**
#'
#'  This import works with an excel file created by HOBOware while calibrating
#'  the MX801 combined DO and Salinity logger.
#'
#'  The excel file should be as created by HOBOware.
#'
#'   Run this:
#'   ```
#'   example_paths <- setup_example_dir(site_filter = "BBC",
#'                                      year_filter = 2025)
#'   deployment_dirs <- example_paths$deployments
#'   print(deployment_dirs)
#'
#'   ```
#'   To create example files that can be inspected and used to run this import
#'   e.g. :
#'   ```
#'   qc_deployment(deployment_dirs[1])
#'
#'   ```
#'
#'   This import now requires a YAML file (`details.yml`) it should look something
#'   like this:
#'   ```
#'   calibration_start: 2025-01-02 15:50:02
#'   calibration_end: 2025-01-04 13:00:02
#'   timezone: EST
#'   serial_number: 22145899
#'   ```
#'   Note `calibration_start` and `calibration_end` define the start and end
#'   of the deployment window. This is a legacy of the U24 and U26 loggers
#'   where the calibrated window and the deployment window were the same.
#'
#'
#'
#' @note
#' `qc_deployment()` calls [import_calibrated_data()] which currently supports
#' three completely different import functions.  See [import_calibrated_data()]
#' for documentation on the data formats they each expect.
#'
#' In all cases input files are looked for within a `Calibration` sub directory
#' to the deployment directory (`dir`).
#'
#' @param dir The path to a deployment directory to run QC on.  It should
#' have a `Calibration/` directory with calibrated DO and conductivity data
#' associated Details files generated by HOBOware.
#'
#' @param report If `TRUE` (the default) an html report will be generated
#' with plots to assist the QAQC process.  Set to `FALSE` to skip generating
#' the report. See [make_deployment_report()] to explicitly make the report
#' as a separate step.
#'
#' @return A list with items:
#' \item{d}{The final tabular data as written to disk.}
#' \item{md}{A nested list of the metadata.}
#' @export
#'
#' @examples
#' \dontrun{
#'   paths <- setup_example_dir()
#'   a <- qc_deployment(paths$deployment)
#'
#' }
#'
qc_deployment <- function(dir, report = TRUE) {

  #============================================================================#
  # Setup                                                                   ####
  #============================================================================#

  #----------------------------------------------------------------------------#
  # Set Paths                                                               ####
  #----------------------------------------------------------------------------#

  paths <- lookup_paths(deployment_dir = dir)
  deployment_date <- paths$deployment_date
  site <- paths$site

  #----------------------------------------------------------------------------#
  # Read parameter and metadata files
  #----------------------------------------------------------------------------#

  # This reads both the global and site specific (later takes precedence)
  # parameter files into bbp, an environment within the package.
  update_bb_parameters(paths)

  # Read placements file
  placements <- read_and_format_placements(paths$placements)

  # Lookup device models
  devices <- lookup_devices(site, deployment_date, placements)

  # Read site table
  sites <- readr::read_csv(paths$sites, col_types = readr::cols(),
                           show_col_types = FALSE)


  # Check that site is in sites table
  if(!site %in% sites$site){
    stop("Site code from file path (", site, ") is not in the sites table: ",
         paths$sites, sep = "")
  }


  if(!file.exists(dir))
    stop("Input deployment directory: ", dir, " does not exist.")

  if(!dir.exists(paths$deployment_cal_dir))
    stop("Expected to find calibration directory:", paths$cal_dir, "\n")

  # Set output paths
  out_paths <- list(
    auto_qc = paths$deployment_auto_qc,
    prelim_qc = paths$deployment_prelim_qc,
    final_qc =  paths$deployment_final_qc,
    metadata = paths$deployment_metadata,
    report = paths$deployment_report
  )

  # Check for prexisting output
  old_output <- unlist(out_paths)[file.exists(unlist(out_paths))]
  if(length(old_output) > 0) {
    stop("Output already exists:\n  ",
         paste(old_output, collapse = "\n  "), sep = "")
  }

  #----------------------------------------------------------------------------#
  # Import data
  #----------------------------------------------------------------------------#
  l <- import_calibrated_data(paths, devices)
  d <- l$d  # merged calibrated data
  md <- l$md # deployment and calibration metadata
  rm(l)


  #----------------------------------------------------------------------------#
  # Reformat - add and rename columns
  #----------------------------------------------------------------------------#


  # Add Date column (as Year-Month-Day text)
  d$Date <- d$Date_Time |>
    lubridate::as_datetime() |>
    lubridate::as_date() |>
    format(format =  "%Y-%m-%d")

  # Add time column  h:m:s
  d$Time <- d$Date_Time |>
    lubridate::as_datetime() |>
    hms::as_hms()



  # Check for missing columns
  # Construct full data frame with all the expected columns in proper order
  # This inserts lots of additional columns that initially have NA
  expected_cols <- get_expected_columns("qc_intermediate", existing = names(d))

  full <- matrix(nrow = nrow(d), ncol = length(expected_cols),
                 dimnames = list(NULL, expected_cols)
  ) |> as.data.frame()
  full[, names(d)] <- d
  d <- full

  # Set site
  d$Site <- site

  #============================================================================#
  # Drop heads and tails (before and after calibration)
  #============================================================================#

  start <- lubridate::as_datetime(md$calibration_start)
  end <- lubridate::as_datetime(md$calibration_end)
  dt <- lubridate::as_datetime(d$Date_Time)

  # Drop uncalibrated
  sv <- dt >= start & dt <= end
  d <- d[sv, , drop = FALSE]

  # Record calibrated pct
  md$pct_calibrated <- round(sum(sv) / length(sv)*100, 4)
  min_calibrated_pct <- 95


  pct_check_types <- c(0, 1) # don't check with 2 (MX801) bc file is often
                                 # much bigger than deployed window

  if(md$import_type %in% pct_check_types && md$pct_calibrated < 95) {
    warning(md$pct_calibrated, "% of the data is calibrated. ",
            " This is lower than the warning threshold of ", min_calibrated_pct, ".")
  }

  # Update calibration column
  # (1 for first and last row because those are the calibration points)
  d$Cal[c(1, nrow(d))] <- 1

  #============================================================================#
  # QC                                                                      ####
  #============================================================================#

  #----------------------------------------------------------------------------#
  # Check basic assumptions
  #----------------------------------------------------------------------------#

  # Check interval length
  temp_dt <- lubridate::as_datetime(d$Date_Time)
  interval <- temp_dt[2] - temp_dt[1]
  units(interval) <- "mins"
  interval_min <- as.numeric(interval)
  rm(temp_dt)

  if(!interval_min == md$logging_interval_min)
    stop("Apparent interval from log (", interval_min," min)",
         " does not match interval from details (",
         md$logging_interval_min, " min).")

  if(!all(order(d$Date) == 1:nrow(d)))
    stop("Log is not in date-time order.")

  # Check that date in deployment folder name matches last date in data
  end_date <- max(d$Date)
  if(end_date != lubridate::as_date(deployment_date))
    stop("Last date in log files: ", end_date,
         " does not match deployment date in path: ", date, sep = "")




  #----------------------------------------------------------------------------#
  # Immediate rejection flags
  #----------------------------------------------------------------------------#

  # 1.	Immediate-rejection flags applied (coded with a final QC code of 9
  #   and skipping the human-review step)
  # a)	Any value of  -888.88  (sensor error indicated)
  # b)	Any temperature
  #              < 5°
  #              > 35°C
  # c)	Raw Conductivity High Range: <1,000
  # d)	Raw Conductivity High Range: >55,000 µS/cm
  # e)	Raw Dissolved Oxygen: >20 mg/L

  # What
  # TD = Temp, DO Logger
  # TC = Temp, Cond Logger
  # HR =  High Range
  # R = Raw DO,
  # D = DO,
  # S = Salinity
  # W = Water depth

  # Error codes
  # e = logger error (immediate rejection)
  # l = low (immediate rejection low)
  # h = high (immediate rejection high)
  # sl = low for site
  # sh = high for site
  # pl = persistently low (low for more than an hour)
  # j = jumps
  # lv = low variation
  # ls = low streak

  # Write empty strings to all the column specific flag columns
  # Exclude aggregated flag column: "FLAGS"
  flag_cols <- grep("Flag$", names(d), value = TRUE)
  for(col in flag_cols)
    d[[col]] <- ""

  # Check for Temperature Immediate Rejection (ir) flags
  d$Temp_DOLog_Flag <- ir_check_temperature(d$Temp_DOLog, "D")
  d$Temp_CondLog_Flag<- ir_check_temperature(d$Temp_CondLog, "C")

  # Check conductivity high range
  d$High_Range_Flag <- ir_check_high_range(d$High_Range)

  # Check raw dissolved oxygen
  d$Raw_DO_Flag <- ir_check_raw_do(d$Raw_DO)

  # Check other columns for error codes
  d$DO_Flag <- ir_check_sensor_error(d$DO, "D")
  d$Salinity_Flag <- ir_check_sensor_error(d$Salinity, "S")

  # Update general flag to indicate immediate rejection
  all_flags <- combine_flags(d)
  d$Gen_QC[all_flags != ""]  <- 9
  rm(all_flags)

  #----------------------------------------------------------------------------#
  # Fouling flags  These trigger review;
  #    they are not immediate rejection flags.
  #----------------------------------------------------------------------------#

  # See Google doc for a discussion of flag definitions
  #
  # https://docs.google.com/spreadsheets/d/1bYxi0nbgDaUsKEyLoj_ry-1Zc-A4MNDfS_J_zH7HiJI/edit#gid=405499625

  d$Temp_DOLog_Flag <- paste0(d$TempDOLog_Flag,
                              check_temperature(x = d$Temp_DOLog,
                                                logger = "D",
                                                site = site,
                                                sites = sites))

  d$Temp_CondLog_Flag <- paste0(d$Temp_CondLog_Flag,
                                check_temperature(x = d$Temp_CondLog,
                                                  logger = "C",
                                                  site = site,
                                                  sites = sites))

  d$Raw_DO_Flag <- paste0(d$Raw_DO_Flag,
                          check_raw_do(x = d$Raw_DO,
                                       site = site,
                                       sites = sites))

  d$DO_Flag <-  paste0(d$DO_Flag,
                       check_do(d$DO,
                                interval = md$logging_interval_min,
                                site = site,
                                sites = sites))


  d$Salinity_Flag <- paste0(d$Salinity_Flag,
                            check_salinity(d$Salinity,
                                           interval = md$logging_interval_min,
                                           site = site,
                                           sites = sites))

  d$DO_Pct_Sat_Flag <- paste0(d$DO_Pct_Sat_Flag,
                               check_do_pct_sat(d$DO_Pct_Sat,
                                                site = site,
                                                sites = sites))




  #----------------------------------------------------------------------------#
  # Calculate flags
  #    combine the data column specific flags into one "Flags" column
  #----------------------------------------------------------------------------#

  d$Flags <- combine_flags(d)

  #----------------------------------------------------------------------------#
  # Update QC Code
  #----------------------------------------------------------------------------#

  # Set 9999 for rows that don't already have a 9 indicating immediate rejection
  # 9999 is a placeholder indicating that the human review needs to
  #    put some other value there.
  d$Gen_QC[is.na(d$Gen_QC) & d$Flags != ""] <- 9999


  #----------------------------------------------------------------------------#
  # Special Case - DEPTH
  #    Has weird interactions with other flags
  #----------------------------------------------------------------------------#
  # Check Depth if present
  #   This affects three columns (GEN_QC, Flags, Depth_QC)
  #  and can possible add a 91 or 9999 to Gen_QC which  will be empty, 9, or 9999
  # When adding to Gen_QC precedence is as follows:
  # A 91 from depth overwrites a 9 from other flags
  # A 91 from depth does not overwrite a 9999 from other flags
  # A 9999 from depth does not overwrite a 9 from other flags.
  # A 91 or 9999 from depth overwrites NA from other flags.

  if ("Depth" %in% names(d)) {
    dc <- check_depth(d$Depth)
    d$Depth_QC <- dc$Depth_QC
    d$Depth_Flag <- dc$Depth_Flag

    use_depth_for_gen_qc <- !is.na(dc$Gen_QC) &
      (is.na(d$Gen_QC) | (d$Gen_QC == 9 &  dc$Gen_QC == 91 ))

    d$Gen_QC[use_depth_for_gen_qc] <- dc$Gen_QC[use_depth_for_gen_qc]

    # Recalculate flags (to incorporate flags from Depth)
    d$Flags <- combine_flags(d)

  }

  #   Record percent rejected and pct flagged in metadata
  md$pct_immediate_rejection <-
    (sum(d$Gen_QC %in% c(9, 91)) / nrow(d) * 100) |>
    round(digits = 2)
  md$pct_flagged_for_review <-  (sum(d$Gen_QC %in% 9999) / nrow(d) * 100) |>
    round(2)
  md$n_records <- nrow(d)


  #----------------------------------------------------------------------------#
  #  Special case, if all Salinity related data is NA (fixed value calibration)
  #  then set DO_Calibration_QC column to 34.
  #----------------------------------------------------------------------------#
  if (all(is.na(d$Salinity))) {
    d$DO_Calibration_QC <- 34
  }

  #----------------------------------------------------------------------------#
  # Select final columns (drop  _flag columns) and put in standard order
  #----------------------------------------------------------------------------#
  final_cols <- get_expected_columns("qc_final", names(d))
  d <- d[, final_cols]

  #----------------------------------------------------------------------------#
  # Write Files
  #----------------------------------------------------------------------------#

  readr::write_csv(d, out_paths$auto_qc, na = "")
  readr::write_csv(d, out_paths$prelim_qc, na = "")
  yaml::write_yaml(md, file = out_paths$metadata)

  used_output <- c("auto_qc", "prelim_qc", "metadata")

  if(report) {
    make_deployment_report(dir, quiet = TRUE)
    used_output <- c(used_output, "report")
  }


  message("\n\nWrote to deployment folder:\n  ", dir,"\n",
          "Files:\n", sep = "")
  message(paste("  ", used_output, ": ", basename(unlist(out_paths[used_output])),
                "\n", sep = ""),
          sep = "")


  message("\nReview and update QC codes in:\n  ", basename(out_paths$prelim_qc),
          "\n", "And rename to:\n  ", basename(out_paths$final_qc), "\n",
          "Then delete the QC report:\n  ", basename(out_paths$report),
          "\n\n",
          sep = "")


  return(invisible(list(d = d, md = md)))

}
# nolint end
