# nolint start: line_length_linter
#' Run automatic quality control on a deployment
#'
#' `qc_deployment()` will:
#' 1. Read the calibrated dissolved oxygen and conductivity files created by
#' HOBOware.
#' 2. Read and parse the associated Details files into nested lists.
#' 3. Reformat and merge the datafiles.
#' 4. Add automatic flags, and create columns for manual QC
#' 5. Write the data and metadata.
#'
#' `qc_deployment()` assumes the files are arranged in a specific
#' [file structure](https://docs.google.com/document/d/1kJttcEXzpNNknGwjkVwdYHw9LzZyjJ-FaX0CrU7H7NU/edit#heading=h.s6vs4d7vj0cn).
#'
#' @note Input files are looked for within `file.path(dir, "Calibration")`
#' using a heuristic that assumes the detail files end in `"Details.txt"`; the
#' data files end in `".csv"`; the dissolved oxygen files have `"DO_"`;
#' the Salinity/Conductivity files have either `"Cond_"`, `"Con_"` or `"Sal_`
#' in the name; and that there is only one of each kind of file - four files
#'  total.
#'
#' @param dir The path to a deployment directory to run QC on.  It should
#' have a `Calibration/` directory with calibrated DO and conductivity data
#' associated Details files generated by HOBOware.
#'
#' @param report If `TRUE` (the default) an html report will be generated
#' with plots to assist the QAQC process.  Set to `FALSE` to skip generating
#' the report. See [make_deployment_report()] to explicitly make the report
#' as a separate step.
#'
#' @return A list with items:
#' \item{d}{The final tabular data as written to disk.}
#' \item{md}{A nested list of the metadata.}
#' @export
#'
#' @examples
#' \dontrun{
#'   paths <- setup_example_dir()
#'   a <- qc_deployment(paths$deployment)
#'
#' }
#'
qc_deployment <- function(dir, report = TRUE) {

  #============================================================================#
  # Setup                                                                   ####
  #============================================================================#

  #----------------------------------------------------------------------------#
  # Set Paths                                                               ####
  #----------------------------------------------------------------------------#

  paths <- lookup_paths(deployment_dir = dir)
  deployment_date <- paths$deployment_date
  site <- paths$site

  #----------------------------------------------------------------------------#
  # Read parameter and metadata files
  #----------------------------------------------------------------------------#

  # This reads both the global and site specific (later takes precedence)
  # parameter files into bbp, an environment within the package.
  update_bb_parameters(paths)

  # Read placements file
  placements <- read_and_format_placements(paths$placements)

  # Lookup device models
  devices <- lookup_devices(site, deployment_date, placements)

  # Read site table
  sites <- readr::read_csv(paths$sites, col_types = readr::cols(),
                           show_col_types = FALSE)


  # Check that site is in sites table
  if(!site %in% sites$site){
    stop("Site code from file path (", site, ") is not in the sites table: ",
         paths$sites, sep = "")
  }


  if(!file.exists(dir))
    stop("Input deployment directory: ", dir, " does not exist.")

  if(!dir.exists(paths$deployment_cal_dir))
    stop("Expected to find calibration directory:", paths$cal_dir, "\n")

  # Set output paths
  out_paths <- list(
    auto_qc = paths$deployment_auto_qc,
    prelim_qc = paths$deployment_prelim_qc,
    final_qc =  paths$deployment_final_qc,
    metadata = paths$deployment_metadata,
    report = paths$deployment_report
  )

  # Check for prexisting output
  old_output <- unlist(out_paths)[file.exists(unlist(out_paths))]
  if(length(old_output) > 0) {
    stop("Output already exists:\n  ",
         paste(old_output, collapse = "\n  "), sep = "")
  }

  #----------------------------------------------------------------------------#
  # Import data
  #----------------------------------------------------------------------------#
  l <- import_calibrated_data(paths, devices)
  d <- l$d  # merged calibrated data
  md <- l$md # deployment and calibration metadata
  rm(l)


  #----------------------------------------------------------------------------#
  # Reformat - add and rename columns
  #----------------------------------------------------------------------------#


  # Add Date column (as Year-Month-Day text)
  d$Date <- d$Date_Time |>
    lubridate::as_datetime() |>
    lubridate::as_date() |>
    format(format =  "%Y-%m-%d")

  # Add time column  h:m:s
  d$Time <- d$Date_Time |>
    lubridate::as_datetime() |>
    hms::as_hms()



  # Check for missing columns
  # Construct full data frame with all the expected columns in proper order
  # This inserts lots of additional columns that initially have NA
  expected_cols <- get_expected_columns("qc_intermediate", existing = names(d))

  full <- matrix(nrow = nrow(d), ncol = length(expected_cols),
                 dimnames = list(NULL, expected_cols)
  ) |> as.data.frame()
  full[, names(d)] <- d
  d <- full

  # Set site
  d$Site <- site

  #============================================================================#
  # Drop heads and tails (before and after calibration)
  #============================================================================#

  start <- lubridate::as_datetime(md$calibration_start)
  end <- lubridate::as_datetime(md$calibration_end)
  dt <- lubridate::as_datetime(d$Date_Time)

  # Drop uncalibrated
  sv <- dt >= start & dt <= end
  d <- d[sv, , drop = FALSE]

  # Record calibrated pct
  md$pct_calibrated <- round(sum(sv) / length(sv)*100, 4)
  min_calibrated_pct <- 95
  if(md$pct_calibrated < 95) {
    warning(md$pct_calibrated, "% of the data is calibrated. ",
            " This is lower than the warning threshold of ", min_calibrated_pct, ".")
  }

  # Update calibration column
  # (1 for first and last row because those are the calibration points)
  d$Cal[c(1, nrow(d))] <- 1

  #============================================================================#
  # QC                                                                      ####
  #============================================================================#

  #----------------------------------------------------------------------------#
  # Check basic assumptions
  #----------------------------------------------------------------------------#

  # Check interval length
  temp_dt <- lubridate::as_datetime(d$Date_Time)
  interval <- temp_dt[2] - temp_dt[1]
  units(interval) <- "mins"
  interval_min <- as.numeric(interval)
  rm(temp_dt)

  if(!interval_min == md$logging_interval_min)
    stop("Apparent interval from log (", interval_min," min)",
         " does not match interval from details (",
         md$logging_interval_min, " min).")

  if(!all(order(d$Date) == 1:nrow(d)))
    stop("Log is not in date-time order.")

  # Check that date in deployment folder name matches last date in data
  end_date <- max(d$Date)
  if(end_date != lubridate::as_date(deployment_date))
    stop("Last date in log files: ", end_date,
         " does not match deployment date in path: ", date, sep = "")




  #----------------------------------------------------------------------------#
  # Immediate rejection flags
  #----------------------------------------------------------------------------#

  # 1.	Immediate-rejection flags applied (coded with a final QC code of 9
  #   and skipping the human-review step)
  # a)	Any value of  -888.88  (sensor error indicated)
  # b)	Any temperature
  #              < 5°
  #              > 35°C
  # c)	Raw Conductivity High Range: <1,000
  # d)	Raw Conductivity High Range: >55,000 µS/cm
  # e)	Raw Dissolved Oxygen: >20 mg/L

  # What
  # TD = Temp, DO Logger
  # TC = Temp, Cond Logger
  # HR =  High Range
  # R = Raw DO,
  # D = DO,
  # S = Salinity

  # Error codes
  # e = logger error (immediate rejection)
  # l = low (immediate rejection low)
  # h = high (immediate rejection high)
  # sl = low for site
  # sh = high for site
  # pl = persistently low (low for more than an hour)
  # j = jumps
  # lv = low variation
  # ls = low streak

  # Write empty strings to all the column specific flag columns
  # Exclude aggregated flag column: "FLAGS"
  flag_cols <- grep("Flag$", names(d), value = TRUE)
  for(col in flag_cols)
    d[[col]] <- ""

  # Check for Temperature Im,ediate Rejection (ir) flags
  d$Temp_DOLog_Flag <- ir_check_temperature(d$Temp_DOLog, "D")
  d$Temp_CondLog_Flag<- ir_check_temperature(d$Temp_CondLog, "C")

  # Check conductivity high range
  d$High_Range_Flag <- ir_check_high_range(d$High_Range)

  # Check raw dissolved oxygen
  d$Raw_DO_Flag <- ir_check_raw_do(d$Raw_DO)

  # Check other columns for error codes
  d$DO_Flag <- ir_check_sensor_error(d$DO, "D")
  d$Salinity_Flag <- ir_check_sensor_error(d$Salinity, "S")

  # Update general flag to indicate immediate rejection
  all_flags <- apply(d[ , flag_cols], 1,  function(x) paste(x, collapse = ""))
  d$Gen_QC[all_flags != ""]  <- 9
  rm(all_flags)

  #----------------------------------------------------------------------------#
  # Fouling flags  These trigger review;
  #    they are not immediate rejection flags.
  #----------------------------------------------------------------------------#

  # See Google doc for a discussion of flag definitions
  #
  # https://docs.google.com/spreadsheets/d/1bYxi0nbgDaUsKEyLoj_ry-1Zc-A4MNDfS_J_zH7HiJI/edit#gid=405499625

  d$Temp_DOLog_Flag <- paste0(d$TempDOLog_Flag,
                              check_temperature(x = d$Temp_DOLog,
                                                logger = "D",
                                                site = site,
                                                sites = sites))

  d$Temp_CondLog_Flag <- paste0(d$Temp_CondLog_Flag,
                                check_temperature(x = d$Temp_CondLog,
                                                  logger = "C",
                                                  site = site,
                                                  sites = sites))

  d$Raw_DO_Flag <- paste0(d$Raw_DO_Flag,
                          check_raw_do(x = d$Raw_DO,
                                       site = site,
                                       sites = sites))

  d$DO_Flag <-  paste0(d$DO_Flag,
                       check_do(d$DO,
                                interval = md$logging_interval_min,
                                site = site,
                                sites = sites))


  d$Salinity_Flag <- paste0(d$Salinity_Flag,
                            check_salinity(d$Salinity,
                                           interval = md$logging_interval_min,
                                           site = site,
                                           sites = sites))

  d$DO_Pct_Sat_Flag <- paste0(d$DO_Pct_Sat_Flag,
                               check_do_pct_sat(d$DO_Pct_Sat,
                                                site = site,
                                                sites = sites))


  #----------------------------------------------------------------------------#
  # Finalize flags
  #    combine the data column specific flags into one "Flags" column
  #----------------------------------------------------------------------------#

  flag_cols <- grep("flag", names(d), ignore.case = TRUE, value = TRUE)
  other_flag_cols <- setdiff(flag_cols, "Flags")

  # Concatenate all the flags into d$Flags
  d$Flags <- apply(
    d[, other_flag_cols], MARGIN = 1,
    FUN = function(x) paste(x[!is.na(x)], collapse = "", sep = ""))

  # Drop trailing ":" from flag columns
  for(col in flag_cols)
    d[[col]] <- gsub(":$", "", d[[col]])

  #----------------------------------------------------------------------------#
  # Update QC Code
  #    and record percent rejected and pct flagged in metadata
  #----------------------------------------------------------------------------#

  # Set 9999 for rows that don't already have a 9 indicating immediate rejection
  # 9999 is a placeholder indicating that the human review needs to
  #    put some other value there.
  d$Gen_QC[is.na(d$Gen_QC) & d$Flags != ""] <- 9999

  md$pct_immediate_rejection <- (sum(d$Gen_QC %in% 9) / nrow(d) * 100) |>
    round(digits = 2)
  md$pct_flagged_for_review <-  (sum(d$Gen_QC %in% 9999) / nrow(d) * 100) |>
    round(2)
  md$n_records <- nrow(d)

  #----------------------------------------------------------------------------#
  #  Special case, if all Salinity related data is NA (fixed value calibration)
  #  then set DO_Calibration_QC column to 34.
  #----------------------------------------------------------------------------#
  if (all(is.na(d$Salinity))) {
    d$DO_Calibration_QC <- 34
  }

  #----------------------------------------------------------------------------#
  # Select final columns (drop  _flag columns) and put in standard order
  #----------------------------------------------------------------------------#
  final_cols <- get_expected_columns("qc_final", names(d))
  d <- d[, final_cols]

  #----------------------------------------------------------------------------#
  # Write Files
  #----------------------------------------------------------------------------#

  readr::write_csv(d, out_paths$auto_qc, na = "")
  readr::write_csv(d, out_paths$prelim_qc, na = "")
  yaml::write_yaml(md, file = out_paths$metadata)

  used_output <- c("auto_qc", "prelim_qc", "metadata")

  if(report) {
    make_deployment_report(dir, quiet = TRUE)
    used_output <- c(used_output, "report")
  }


  message("\n\nWrote to deployment folder:\n  ", dir,"\n",
          "Files:\n", sep = "")
  message(paste("  ", used_output, ": ", basename(unlist(out_paths[used_output])),
                "\n", sep = ""),
          sep = "")


  message("\nReview and update QC codes in:\n  ", basename(out_paths$prelim_qc),
          "\n", "And rename to:\n  ", basename(out_paths$final_qc), "\n",
          "Then delete the QC report:\n  ", basename(out_paths$report),
          "\n\n",
          sep = "")


  return(invisible(list(d = d, md = md)))

}
# nolint end
